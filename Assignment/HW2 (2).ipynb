{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 HW 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Due: Tuesday Oct 8 @ 11:59 PM EST\n",
    "\n",
    "Extra Credit Deadline: Sunday Oct 6 @ 11:59 PM EST\n",
    "\n",
    "Earliest Possible Submission: Tuesday Sep 24\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to Gradescope (this can also be done via the assignment on Canvas).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh `Kernel > Restart & Run All` just before uploading the `ipynb` file to gradescope. **In addition:**\n",
    "- Make sure your name is entered above\n",
    "- Make sure you comment your code effectively\n",
    "- If problems are difficult for the TAs/Profs to grade, you will lose points\n",
    "\n",
    "### Tips for success\n",
    "- Start early\n",
    "- Make use of Piazza (also accessible through Canvas)\n",
    "- Make use of Office Hours\n",
    "- Remember to use cells and headings to make the notebook easy to read (if a grader cannot find the answer to a problem, you will receive no points for it)\n",
    "- Under no circumstances may one student view or share their ungraded homework or quiz with another student [(see also)](http://www.northeastern.edu/osccr/academic-integrity), though you are welcome to **talk about** (*not* show each other your answers to) the problems.\n",
    "\n",
    "### Finally:\n",
    "\n",
    "I designed this homework to provide **less** guidance in each subsequent part; this is on purpose, so that you slowly get used to thinking more critically about how to approach the various tasks. If you are confused as you are working, especially with the later parts, please don't hesitate to reach out for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Sunrise-Sunset API\n",
    "\n",
    "This first part of the homework asks you to complete the pipeline which, given the lattitude / longitude and timezone of some cities:\n",
    "\n",
    "``` python\n",
    "loc_dict = {'Boston': (42.3601, -71.0589, 'US/Eastern'),\n",
    "            'Lusaka': (-15.3875, 28.3228, 'Africa/Lusaka'),\n",
    "            'Sydney': (-33.8688, 151.2093, 'Australia/Sydney')}\n",
    "```\n",
    "\n",
    "the keys are the `name` of the city and the values are tuples of `lat, lon, timezone_name\n",
    "\n",
    "is able to:\n",
    "- query a sunrise / sunset API\n",
    "- clean and process data (timezone management & building `datetime` objects)\n",
    "- For extra credit: produce the a graph of daylight through the year like this:\n",
    "\n",
    "<img src=\"https://i.ibb.co/CBhWtCY/newdaylight.png\" alt=\"newdaylight\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.1: Getting Sunrise Sunset via API (5 points)\n",
    "Write the `get_sunrise_sunset()` function below so that it uses [this sunrise sunset API](https://sunrise-sunset.org/api) to produce the output (the dictionary) shown in the test case below so that it passes the case.\n",
    "\n",
    "It may be helpful to know that this particular API...\n",
    "- requires no api key\n",
    "- returns about 2.5 queries per second\n",
    "- did not block me when I tried to make 100 consecutive calls as quickly as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have these modules installed\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to write a good docstring! I will do this for you for the other functions in this homework, but you should practice here!\n",
    "def get_sunrise_sunset(lat, lng, date):\n",
    "    \"\"\" WRITE YOUR DOCSTRING HERE\n",
    "    \"\"\"   \n",
    "    \n",
    "    # WRITE YOUR FUNCTIONS HERE AND DELETE THE PASS BELOW\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_dict = get_sunrise_sunset(lat=42.3601, lng=-71.0589, date='2022-02-15')\n",
    "sun_dict_expected = \\\n",
    "{'results': {'sunrise': '11:38:48 AM',\n",
    "            'sunset': '10:17:50 PM',\n",
    "            'solar_noon': '4:58:19 PM',\n",
    "            'day_length': '10:39:02',\n",
    "            'civil_twilight_begin': '11:11:30 AM',\n",
    "            'civil_twilight_end': '10:45:08 PM',\n",
    "            'nautical_twilight_begin': '10:38:37 AM',\n",
    "            'nautical_twilight_end': '11:18:00 PM',\n",
    "            'astronomical_twilight_begin': '10:06:05 AM',\n",
    "            'astronomical_twilight_end': '11:50:33 PM'},\n",
    " 'status': 'OK',\n",
    " 'tzid': 'UTC',\n",
    " 'lat-lng': (42.3601, -71.0589),\n",
    " 'date': '2022-02-15'}\n",
    "\n",
    "assert sun_dict == sun_dict_expected, 'get_sunrise_sunset() error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2 Timezone Considerations: (5 points)\n",
    "\n",
    "It may appear the test case above works, but a look at the API's documentation reminds us: \n",
    "\n",
    "    \"NOTE: All times are in UTC and summer time adjustments are not included in the returned data.\"\n",
    "    \n",
    "Meaning that we would need to change the timezone ourself if comparing different locations. \n",
    "\n",
    "Complete the `change_tz()` below so that it passes the given test case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need these\n",
    "import pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have started the function for you\n",
    "def change_tz(dt, timezone_from, timezone_to):\n",
    "    \"\"\" converts timezone of a timezone naive datetime object\n",
    "    \n",
    "    Args:\n",
    "        dt (datetime): datetime (or time) object without timezone\n",
    "        timezone_from (str): timezone of input\n",
    "        timezone_to (str): timezone of output datetime\n",
    "        \n",
    "    Returns:\n",
    "        dt (datetime): datetime object corresponding to \n",
    "            unix_time\n",
    "    \"\"\"\n",
    "    \n",
    "    dt_from = pytz.timezone(timezone_from).localize(dt)\n",
    "    # complete the function and remove the pass below\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test case input / output\n",
    "dt_no_tz = datetime(2021, 2, 13, 9, 54, 4, 270088)\n",
    "dt_expect = datetime(2021, 2, 13, 14, 54, 4, 270088, tzinfo=pytz.timezone('GMT'))\n",
    "\n",
    "# compute actual output\n",
    "dt = change_tz(dt_no_tz, timezone_from='US/Eastern', timezone_to='GMT')\n",
    "\n",
    "assert dt == dt_expect, 'change_tz() error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test case input / output\n",
    "dt_no_tz = datetime(2021, 2, 13, 9, 54, 4, 270088)\n",
    "dt_expect = datetime(2021, 2, 13, 9, 54, 4, 270088, tzinfo=pytz.timezone('GMT'))\n",
    "\n",
    "# compute actual output\n",
    "dt = change_tz(dt_no_tz, timezone_from='GMT', timezone_to='GMT')\n",
    "\n",
    "assert dt == dt_expect, 'change_tz() error'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3: Turning the dictionary into a Series (5 points)\n",
    "Build `clean_sun_dict()` to pass each of the two test cases below.  Note that:\n",
    "- sunrise and sunset are `time` objects which account for daylight's saving:\n",
    "    - include the date when building these objects\n",
    "    - use `change_tz()` above to cast them to the proper timezone\n",
    "    - build `time` objects by calling `datetime.time()` to discard the date of a `datetime`\n",
    "    - importing `pandas as pd` and using `pd.to_datetime` may also be helpful\n",
    "- `sunrise_hr` and `sunset_hr` are the hours since the day began in local timezone (more easily graphed)\n",
    "    - you may use `.strftime()` and `int()` to cast time objects to strings and then integers (which may be helpful) \n",
    "    \n",
    "**NOTE:** There may be more than one way to accomplish writing this function; as long as the function passes both `assert` test cases, you may continue. Just do be sure to comment and present your code as cleanly as possible. **NOTE ALSO** that because of the way *I* made the solution, the `sunrise_hr` and `sunset_hr` values are rounded strangely. If you are getting something *close*, you **may** change the test case to match your so that the `assert` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sun_dict(sun_dict, timezone_to):\n",
    "    \"\"\" builds pandas series and cleans output of API\n",
    "    \n",
    "    Args:\n",
    "        sun_dict (dict): dict of json (see ex below)\n",
    "        timezone_to (str): timezone of outputs (API returns\n",
    "            UTC times)\n",
    "            \n",
    "    Returns:\n",
    "        sun_series (pd.Series): all times converted to\n",
    "            time objects\n",
    "    \n",
    "    example sun_series:\n",
    "    \n",
    "    date            2021-02-13 00:00:00\n",
    "    lat-lng        (36.72016, -4.42034)\n",
    "    sunrise                    02:11:06\n",
    "    sunrise_hr                    2.185\n",
    "    sunset                     13:00:34\n",
    "    sunset_hr                   13.0094\n",
    "    dtype: object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Function content here, remove pass below\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_dict = {'results': {'sunrise': '11:38:48 AM',\n",
    "                        'sunset': '10:17:50 PM',\n",
    "                        'solar_noon': '4:58:19 PM',\n",
    "                        'day_length': '10:39:02',\n",
    "                        'civil_twilight_begin': '11:11:30 AM',\n",
    "                        'civil_twilight_end': '10:45:08 PM',\n",
    "                        'nautical_twilight_begin': '10:38:37 AM',\n",
    "                        'nautical_twilight_end': '11:18:00 PM',\n",
    "                        'astronomical_twilight_begin': '10:06:05 AM',\n",
    "                        'astronomical_twilight_end': '11:50:33 PM'},\n",
    "             'status': 'OK',\n",
    "             'lat-lng': (42.3601, -71.0589),\n",
    "             'date': '2022-02-15'}\n",
    "\n",
    "# test without timezone conversion\n",
    "sun_series = clean_sun_dict(sun_dict, timezone_to='GMT')\n",
    "\n",
    "sun_series_exp = pd.Series(\n",
    "{'date': datetime(year=2022, month=2, day=15),\n",
    "'lat-lng': (42.3601, -71.0589),\n",
    "'sunrise': time(hour=11, minute=38, second=48),\n",
    "'sunrise_hr': 11.646666666666667,\n",
    "'sunset': time(hour=22, minute=17, second=50),\n",
    "'sunset_hr': 22.297222222222224})\n",
    "\n",
    "assert sun_series.eq(sun_series_exp).all(), 'clean_sun_dict() error (GMT)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with timezone conversion\n",
    "sun_series = clean_sun_dict(sun_dict, timezone_to='US/Eastern',)\n",
    "\n",
    "sun_series_exp = pd.Series(\n",
    "{'date': datetime(year=2022, month=2, day=15),\n",
    "'lat-lng': (42.3601, -71.0589),\n",
    "'sunrise': time(hour=6, minute=38, second=48),\n",
    "'sunrise_hr': 6.6466666666666665,\n",
    "'sunset': time(hour=17, minute=17, second=50),\n",
    "'sunset_hr': 17.297222222222224})\n",
    "\n",
    "assert sun_series.eq(sun_series_exp).all(), 'clean_sun_dict() error (EST)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.4: Getting our Data Frame (5 points)\n",
    "\n",
    "Write the `get_annual_sun_data()` function so that it produces the outputs shown below.  This function should make use of:\n",
    " - `get_sunrise_sunset()`\n",
    " - `clean_sun_dict()`\n",
    "   \n",
    "as built above. I will start the function for you to help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following snippet:\n",
    "\n",
    "```python\n",
    "loc_dict = {'Boston': (42.3601, -71.0589, 'US/Eastern'),\n",
    "            'Lusaka': (-15.3875, 28.3228, 'Africa/Lusaka'),\n",
    "            'Sydney': (-33.8688, 151.2093, 'Australia/Sydney')}\n",
    "df_annual_sun = get_annual_sun_data(loc_dict, year=2021, period_day=30)\n",
    "df_annual_sun.head(6)\n",
    "```\n",
    "\n",
    "should generate:\n",
    "\n",
    "|    |   city |       date |              lat-lng |  sunrise | sunrise_hr |   sunset | sunset_hr |\n",
    "|---:|-------:|-----------:|---------------------:|---------:|-----------:|---------:|----------:|\n",
    "|  0 | Boston | 2021-01-01 |  (42.3601, -71.0589) | 07:11:49 |   7.196944 | 16:24:12 | 16.403333 |\n",
    "|  1 | Lusaka | 2021-01-01 |  (-15.3875, 28.3228) | 05:38:33 |   5.642500 | 18:42:09 | 18.702500 |\n",
    "|  2 | Sydney | 2021-01-01 | (-33.8688, 151.2093) | 05:46:24 |   5.773333 | 20:10:53 | 20.181389 |\n",
    "|  3 | Boston | 2021-01-31 |  (42.3601, -71.0589) | 06:56:43 |   6.945278 | 16:58:42 | 16.978333 |\n",
    "|  4 | Lusaka | 2021-01-31 |  (-15.3875, 28.3228) | 05:55:43 |   5.928611 | 18:44:35 | 18.743056 |\n",
    "|  5 | Sydney | 2021-01-31 | (-33.8688, 151.2093) | 06:14:24 |   6.240000 | 20:02:42 | 20.045000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could be useful\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annual_sun_data(loc_dict, year=2021, period_day=30): \n",
    "    \"\"\" pulls evenly spaced sunrise / sunsets from API over year per city\n",
    "    \n",
    "    Args:\n",
    "        loc_dict (dict): keys are cities, values are tuples of \n",
    "            (lat, lon, tz_str) where tz_str is a timezone\n",
    "            string included in pytz.all_timezones\n",
    "        year (int): year to query\n",
    "        period_day (int): how many days between data queries\n",
    "            (i.e. period_day=1 will get every day for the year)\n",
    "            \n",
    "    Returns:\n",
    "        df_annual_sun (DataFrame): each row represents a \n",
    "            sunrise / sunset datapoint, see get_sunrise_sunset()\n",
    "    \"\"\"\n",
    "\n",
    "    cycle_day = pd.to_datetime(f'{year}-01-01')\n",
    "    cycle_city = loc_dict.keys()\n",
    "    df_annual_sun = pd.DataFrame()\n",
    "    \n",
    "    while cycle_day.year == year:\n",
    "        for city in cycle_city:\n",
    "            city_series = pd.Series({'city': city})\n",
    "\n",
    "            #continue the for loop, using the two functions you've already written\n",
    "\n",
    "        #continue the while loop until you reach the end of the year\n",
    "    \n",
    "    # remove the pass below and include a return statement\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_dict = {'Boston': (42.3601, -71.0589, 'US/Eastern'),\n",
    "            'Lusaka': (-15.3875, 28.3228, 'Africa/Lusaka'),\n",
    "            'Sydney': (-33.8688, 151.2093, 'Australia/Sydney')}\n",
    "\n",
    "# you may find that setting period_day to a larger value is quicker for debug\n",
    "# period_day=5 takes about a minute or so given the API does 2-3 requests / sec\n",
    "df_annual_sun = get_annual_sun_data(loc_dict, year=2021, period_day=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annual_sun.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.5: Plotting the data (5 points)\n",
    "\n",
    "Using [plt.fillbetween()](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.fill_between.html), like [this example](https://colab.research.google.com/drive/1eYuuwGwQKEa6x84fqpdVlf46sXLDmhCZ?usp=sharing), write the `plot_daylight()` function so that:\n",
    "\n",
    "``` python\n",
    "plot_daylight(df_annual_sun)\n",
    "```\n",
    "\n",
    "produces a similar graph to:\n",
    "\n",
    "<img src=\"https://i.ibb.co/CBhWtCY/newdaylight.png\" alt=\"newdaylight\" style=\"width: 500px;\"/>\n",
    "\n",
    "Be sure that your graph displays in Jupyter notebook (no need to save it in another form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules you might use\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.2)\n",
    "\n",
    "def plot_daylight(df_annual_sun):\n",
    "    \"\"\" produces a plot of daylight seen across cities\n",
    "    \n",
    "    Args:\n",
    "        df_annual_sun (DataFrame): each row represents a \n",
    "            sunrise / sunset datapoint, see get_sunrise_sunset()\n",
    "    \"\"\"\n",
    "    \n",
    "    # Function content here, remove pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about a minute to run with period_day=7, worth the wait to characterize\n",
    "# the sudden jumps due to daylight savings times\n",
    "df_annual_sun = get_annual_sun_data(loc_dict, year=2021, period_day=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_daylight(df_annual_sun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Spotify API (Spotipy)\n",
    "\n",
    "**Note**: The following is copied verbatim from the end of Day2_APIs on Canvas.\n",
    "\n",
    "The Spotify API is quite powerful and gives us access to any song/artist in its libraries, plus even more information that you might not have thought of. There is also a module that has been created to access the API within python. Open up a terminal (or do it in jupyter notebook; this is a magic module) and run:\n",
    "\n",
    "`pip install spotipy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after installation\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with OpenWeather, we need to make an account [here](https://developer.spotify.com/) (this is essentially the same as making a regular Spotify account) and then get an API key (Spotify requires two things, actually, a Client ID and a secret key). At the above website, go to:\n",
    "\n",
    "- Dashboard\n",
    "- Log into your Spotify account (make one if you don't have one)\n",
    "- Accept the terms of using the API\n",
    "- Create an app (you can call it anything, I called mine `DS3000_Spotify`)\n",
    "- Enter `http://localhost/` when it prompts you for a Redirect URI\n",
    "- Get a client ID (mine is `592acf2d2dc84d94bbc652f2f1d72375`, though it is usually good practice to **not** share this) and a client secret (**never share this with anyone**: save it in a separate file like we did with our OpenWeather API key earlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists a file `spotify_secret.py` in same directory as this jupyter notebook which contains:\n",
    "    \n",
    "    secret = 'professorgerberssecretspotify'\n",
    "\n",
    "**Put your own secret in the `secret = ` and save your file as `spotify_secret.py` in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure you have named your file spotify_secret.py\n",
    "from spotify_secret import secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "# Make sure you use your OWN client ID (DO NOT leave mine in there!!)\n",
    "cid = '592acf2d2dc84d94bbc652f2f1d72375'\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager = client_credentials_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.1: Uniform Resource Identifiers (URI) (5 points)\n",
    "\n",
    "An important component of using the Spotify API is the use of the uniform resource identifiers, pointing at each object in the API. We need a URI to perform any function with the API referring to an object in Spotify. The URI of any Spotify object is contained in its shareable link. For example, the link to the Global top songs playlist, when found from the Spotify desktop application, is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you receive a couldn't read cache or write token error, it should simply be a warning and not be a problem\n",
    "playlist_link = \"https://open.spotify.com/playlist/37i9dQZF1DXcBWIGoYBM5M\"\n",
    "playlist_URI = playlist_link.split(\"/\")[-1].split(\"?\")[0]\n",
    "track_uris = [x[\"track\"][\"uri\"] for x in sp.playlist_tracks(playlist_URI)[\"items\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at a single track from the playlist\n",
    "# it is commented out because it will produce a lot of output! You can uncomment it out to see what it looks like.\n",
    "\n",
    "#sp.playlist_tracks(playlist_URI)[\"items\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Getting to Know You form, I asked what your favorite song was. Below is the url for the Spotify playlist created from those songs. Read it into python the way we did the above playlist.\n",
    "\n",
    "`playlist_link = \"https://open.spotify.com/playlist/3lDbfa8bVjjcpJtFIoHBv2?si=bc1a57aa591742cd\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that you may only get the first 100 songs\n",
    "# check out the spotipy documentation if you want to try to get the full playlist, though the first 100 is perfectly fine for this HW\n",
    "len(track_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2: Build a dictionary of track info (5 points)\n",
    "\n",
    "I have initialized the `playlist_dict` dictionary for you below, complete with keys and empty lists. Use a for loop to loop through the tracks in our class's playlist and `.append()` the associated values for each track to each of the lists, building out the dictionary. You may write a function to do this, but you don't have to (I didn't). **Note**: if you know of a faster way to do this than with a for loop, you are welcome to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_dict = {'track_uri': list(),\n",
    "                'track_name': list(),\n",
    "                'artist_uri': list(),\n",
    "                'artist_name': list(),\n",
    "                'artist_pop': list(),\n",
    "                'artist_genres': list(),\n",
    "                'album': list(),\n",
    "                'track_pop': list()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(playlist_dict['track_uri'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.3: Extracting Features from Tracks (5 points)\n",
    "\n",
    "Now that we have a list of track URIs, we can extract features from these tracks. Spotify has a list of these features for each of its tracks, from analysis of the audio. We can access these with a single method of the spotify object `audio_features(uri)`. This gives us a list of mostly numerical features that we can use for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that .audio_features returns a dictionary in a list of 1\n",
    "sp.audio_features(playlist_dict['track_uri'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have initiated an empty `song_dict` for you below. Loop through the track URIs of our `playlist_dict` from the previous part then for each song, loop through the audio features and add corresponding key-value pairs to the dictionary. Finally, after you have created the dictionary, cast it to a Data Frame called `song_df` using pandas. **Note**: if you know of a faster way to do this than with a nested for loop, you are welcome to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "song_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# uncomment the below to see if you completed your task\n",
    "# song_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.4: Cleaning/manipulating (5 points)\n",
    "\n",
    "Look at the information in `playlist_dict` and the information in `song_df`. What information would you like to add to `song_df` from `playlist_dict`? What information is in `song_df` that is not very useful?\n",
    "\n",
    "**Briefly discuss** your answers to those two questions in a markdown cell, then make the changes to `song_df`. That is: add the columns to the Data Frame that you wish to add, and delete the columns that are not useful. Keep in mind that there are many \"correct\" answers here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.5: Plotting (5 points)\n",
    "\n",
    "Using plotly, make two plots (in separate code cells):\n",
    "- of energy (x-axis) versus danceability (y-axis) that has the song title as hover data.\n",
    "- of acousticness (x-axis) versus loudness (y-axis) that has the song title as hover data.\n",
    "\n",
    "**Then**, in a markdown cell, discuss the relationships (if any) you see in these plots and whether those relationships make sense to you/what you would have expected to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Web Scraping Fantasy Football\n",
    "\n",
    "## Part 3.1: Get a table (5 points)\n",
    "\n",
    "In Fantasy Football, real NFL players gain points for fans at home based on some scoring criteria (which differs based on the website, but in all cases more points is better). Use the `pd.read_html` function to pull in the table located at the following url from Week 1 of the current Yahoo Fantasy Football season: https://football.fantasysports.yahoo.com/f1/whoshot?pos=ALL&week=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.2: Build a clean Data Frame (10 points)\n",
    "\n",
    "Write a function `clean_nfl_df()` which takes the table from Part 3.1 as input and :\n",
    "\n",
    "- breaks up the `Name` column into three columns: `Name`, `Team`, `Pos` (position). For example, the first couple observations under the `Name` column as it is read in by default should be:\n",
    "\n",
    "| Name                                                                  |\n",
    "|----------------------------------------------------------------------:|\n",
    "| Saquon BarkleyPhi - RB Final W 34-29 vs GB  Video ForecastPlayer Note |\n",
    "| Josh AllenBuf - QB Final W 34-28 vs Ari  Video ForecastPlayer Note    |\n",
    "\n",
    "    this should be replaced with three columns:\n",
    "\n",
    "| Name             | Team | Pos |\n",
    "|-----------------:|-----:|----:|\n",
    "| Saquon Barkley   | Phi  | RB  |\n",
    "| Josh Allen       | Buf  | QB  |\n",
    "\n",
    "- breaks up the `Stats` column into different numeric columns based on the statistics. There should be:\n",
    "    * `Pass Yds`\n",
    "    * `Rec Yds`\n",
    "    * `Rush Yds`\n",
    "    * `Pass TD`\n",
    "    * `Rec TD`\n",
    "    * `Rush TD`\n",
    "    * `Rec`\n",
    "    * `Sack`\n",
    "    * `Int`\n",
    "    * `Fum Rec`\n",
    "    \n",
    "    so that the first couple observations:\n",
    "    \n",
    "| Stats                               |\n",
    "|------------------------------------:|\n",
    "| 109 Rush Yds, 2 Rush TD, 2 Rec      |\n",
    "| 232 Pass Yds, 2 Pass TD, 39 Rush Yds|\n",
    "\n",
    "    becomes\n",
    "    \n",
    "| Pass Yds | Rec Yds | Rush Yds | Pass TD | Rec TD | Rush TD | Rec | Sack | Int | Fum Rec |\n",
    "|---------:|--------:|---------:|--------:|-------:|--------:|----:|-----:|----:|--------:|\n",
    "|   NaN    |  NaN    |    109   |   NaN   | NaN    | 2       | 2   | NaN  | NaN | NaN     |\n",
    "|   232    |  NaN    |     39   |   2     | NaN    | NaN     | NaN | NaN  | NaN | NaN     |\n",
    "\n",
    "- produces the final clean data frame whose first two rows look like (**Note** the final `Fan Pts` column):\n",
    "\n",
    "| Name             | Team | Pos | Pass Yds | Rec Yds | Rush Yds | Pass TD | Rec TD | Rush TD | Rec | Sack | Int | Fum Rec | Fan Pts   |\n",
    "|-----------------:|-----:|----:|---------:|--------:|---------:|--------:|-------:|--------:|----:|-----:|----:|--------:|----------:|\n",
    "| Saquon Barkley   | Phi  | RB  |   NaN    |  NaN    |    109   |   NaN   | NaN    | 2       | 2   | NaN  | NaN | NaN     |  32.20    |\n",
    "| Josh Allen       | Buf  | QB  |   232    |  NaN    |     39   |   2     | NaN    | NaN     | NaN | NaN  | NaN | NaN     |  31.18    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Help\n",
    "Below is an example of using regular expressions in Python which should help you figure out part of what is needed for this problem. You do not need to understand this fully, just figure out where to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "\n",
    "# Example string\n",
    "s1 = 'First NameTeam'\n",
    "# Some teams may have all caps strings, so this can adjust that\n",
    "s2 = 'First NameTEAM'\n",
    "\n",
    "# (try this with both s1 and s2 to make sure it works)\n",
    "# Use regular expression to split at uppercase letters \n",
    "match = re.search(r'(?:[A-Z][a-z]*|[A-Z]+)$', s2)\n",
    "name = s2[:match.start()].strip()\n",
    "team = match.group()\n",
    "    \n",
    "print(name)\n",
    "print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.3: More Cleaning (5 points)\n",
    "\n",
    "Go to the url from Part 2.1 in the browser and examine how the url changes when different positions or weeks are selected. Then, write the function `weekly_nfl_df()` which takes two arguments `pos` and `week`, and which uses your `clean_nfl_df()` function from Part 2.1 to produce a clean data frame for any position and any week (depending on when you complete this, there have only been 2-5 weeks so far; thus when you test this function only use 1 or 2 to be safe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.4: Using the function (5 points)\n",
    "\n",
    "Use your `weekly_nfl_df()` function from Part 2.3 to create a single data frame that includes the top fantasy Quarterbacks (`pos = 'QB'`) for the first 3 weeks of this season. **Note**: there may be multiple ways to do this, and you **must** wait until the morning of September 24 to be able to do all three weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.5: Plotting and Interpretation (5 points)\n",
    "\n",
    "Make a graph which plots `Pass Yds` on the x-axis against `Fan Pts` on the y-axis, and colors the points based on `Pass TD`. Use `plotly` and include the `Name` and `Team` as `hover_data`. Make sure the graph is well labeled, titled, and includes a legend. Then, in a Markdown cell, discuss in **at least 3** sentences your interpretation of the graph.\n",
    "\n",
    "- **Note**: if you are not an american football fan, in brief the Quarterback's role is to throw the ball to other players in the hopes of scoring a touchdown (if you want a much more technical description, you may also read a bit [here](https://en.wikipedia.org/wiki/Quarterback))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3.6: More Plotting and Interpretation (5 points)\n",
    "\n",
    "Use the `weekly_nfl_df()` function to create data frames for each of the four main offensive positions (QB, WR, RB, TE) **for the first three weeks** and then create, using subplots in a single plot, histograms for each positions' `Fan Pts`. Make sure the subplots are on the same scale, well labeled, and titled. Discuss the results in a few short sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Web Scraping EuroMillions Results Continued...\n",
    "\n",
    "For this problem, we continue with creating a small data set scraped from [Euro-Millions](https://www.euro-millions.com/) which is a lottery that is played across nine European countries. Draws take place on Tuesday and Friday evenings with a minimum guaranteed jackpot of â‚¬17 million. **The beginning of this problem was on Lab 1; you will need to use the functions you built for Part 2 to complete this assignment**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the below with the corresponding function from Lab 1, Part 2.1\n",
    "\n",
    "def get_lottery_html(code):\n",
    "    \n",
    "    pass\n",
    "\n",
    "url_text = get_lottery_html('13-09-2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the below with the corresponding function from Lab 1, Part 2.2\n",
    "\n",
    "def get_country_soup(html, country):\n",
    "    \n",
    "    pass\n",
    "\n",
    "country_choice = 'BE'\n",
    "my_country_soup = get_country_soup(url_text, country_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.1: Cleaning a Country (5 points)\n",
    "\n",
    "Below is the function `clean_country_df()`, which takes the soup object from the previous function and creates a data frame with the following columns:\n",
    "\n",
    "    - `balls`: the number of balls matched\n",
    "    - `stars`: the number of stars matched\n",
    "    - `ppw`: the prize per winner\n",
    "    - `country_winners`: how many winners of the prize in the given country\n",
    "    - `total_winners`: the total number of winners\n",
    "    - `country`: the country name\n",
    "    - `currency`: the currency of the lottery\n",
    "\n",
    "I have written the function and (*given your functions from lab works*) it should work. **DO NOT CHANGE ANYTHING IN THE BODY OF THE FUNCTION.**\n",
    "\n",
    "**In a markdown cell** create a bullet point list where you explain each what each chunk of code does. Your bullet point list should have **THREE** sections, with **NINE** total bullet points/explanations corresponding to the chunks below the `# EXPLAIN THIS (number)` comments. You must accurately summarize the content of each code chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "import re\n",
    "\n",
    "def clean_country_df(soup, country_name = \"BE\"):\n",
    "    \"\"\"Takes the soup of a country and cleans it, creating a data frame.\n",
    "    \n",
    "    Args:\n",
    "        soup (soup): the soup from get_country_soup\n",
    "        country_name (str): name of the country (make sure this matches with the code used in the previous part)\n",
    "\n",
    "    Returns:\n",
    "        clean_country_df (DataFrame): a DataFrame with seven columns corresponding to\n",
    "            balls matched\n",
    "            stars matched\n",
    "            prize per winner\n",
    "            country winners\n",
    "            total winners\n",
    "            country\n",
    "            currency\n",
    "    \"\"\"\n",
    "    # EXPLAIN THIS (1.1)\n",
    "    table = soup.find('table')\n",
    "\n",
    "    # EXPLAIN THIS (1.2)\n",
    "    headers = [th.get_text(strip=True) for th in table.find('thead').find_all('th')]\n",
    "\n",
    "    # EXPLAIN THIS (1.3)\n",
    "    country_winner_index = next((i for i, header in enumerate(headers) if 'Winners' in header and 'Total' not in header), None)\n",
    "\n",
    "    # EXPLAIN THIS (1.4)\n",
    "    balls_matched = []\n",
    "    stars_matched = []\n",
    "    prize_per_winner = []\n",
    "    country_winners = []\n",
    "    total_winners = []\n",
    "    currencies = []\n",
    "    \n",
    "    # Process each row in the table body, excluding the last totals row\n",
    "    for row in table.find('tbody').find_all('tr')[:-1]:\n",
    "        columns = row.find_all('td')\n",
    "        \n",
    "        # EXPLAIN THIS (2.1)\n",
    "        numbers_matched = columns[0].get_text(strip=True)\n",
    "        prize = columns[1].get_text(strip=True)\n",
    "        country_winner = columns[country_winner_index].get_text(strip=True) if country_winner_index is not None else 'N/A'\n",
    "        total_winner = columns[-1].get_text(strip=True)\n",
    "        \n",
    "        # EXPLAIN THIS (2.2)\n",
    "        currency_match = re.match(r'^\\D*', prize)\n",
    "        currency = currency_match.group(0) if currency_match else 'N/A'\n",
    "        currencies.append(currency)\n",
    "        \n",
    "        # EXPLAIN THIS (2.3)\n",
    "        numeric_prize = pd.to_numeric(prize.replace(currency, '').replace(',', ''), errors='coerce')\n",
    "        \n",
    "        # EXPLAIN THIS (2.4)\n",
    "        numbers_split = numbers_matched.split('+')\n",
    "        balls = pd.to_numeric(numbers_split[0].strip().replace(',', ''), errors='coerce')\n",
    "        stars = pd.to_numeric(numbers_split[1].strip().replace(',', ''), errors='coerce') if len(numbers_split) > 1 else 0\n",
    "\n",
    "        balls_matched.append(balls)\n",
    "        stars_matched.append(stars)\n",
    "        prize_per_winner.append(numeric_prize)\n",
    "        country_winners.append(pd.to_numeric(country_winner.replace(',', ''), errors='coerce'))\n",
    "        total_winners.append(pd.to_numeric(total_winner.replace(',', ''), errors='coerce'))\n",
    "    \n",
    "    # EXPLAIN THIS (3)\n",
    "    data = {\n",
    "        'balls': balls_matched,\n",
    "        'stars': stars_matched,\n",
    "        'ppw': prize_per_winner,\n",
    "        'country_winners': country_winners,\n",
    "        'total_winners': total_winners,\n",
    "        'country': [country_name] * len(balls_matched),\n",
    "        'currency': currencies\n",
    "    }\n",
    "    \n",
    "    clean_country_df = pd.DataFrame(data)\n",
    "    \n",
    "    return clean_country_df\n",
    "\n",
    "# Example usage\n",
    "clean_df = clean_country_df(my_country_soup, 'BE')\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer in this cell:\n",
    "- Explain Code Chunks 1:\n",
    "  \n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "- Explain Code Chunks 2:\n",
    "  \n",
    "    -\n",
    "    -\n",
    "    -\n",
    "    -\n",
    "- Explain Code Chunk 3:\n",
    "\n",
    "    -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.2: Stacking the Countries (5 points)\n",
    "\n",
    "Complete the function `stack_countries_df()` below (including docstring) which takes as an argument a list of country codes (strings) and a list of dates (strings), and uses the functions from the previous three parts to create a single data frame with results across those countries and dates. There may be multiple ways to do this, but one way could be to first loop through the dates, use the `get_lottery_html()` function, then loop through the countries and apply the other two functions. You will also want to add a column with the date information to the final data frame.\n",
    "\n",
    "**Make sure to remove the `pass` statement when you are finished.** Then, also make sure to run the code to ensure your function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_countries_df(country_list, date_list):\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = ['BE', 'GB', 'CH']\n",
    "dates = ['26-04-2024', '30-04-2024']\n",
    "combined_df = stack_countries_df(country_codes, dates)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4.3: EDA and Data Viz (5 points)\n",
    "\n",
    "The first code cell below runs your function from part 4 to get the lottery results for Belgium and France over the month of April 2024. Use this data frame to:\n",
    "\n",
    "- Create a subset which contains only the 5 ball, 0 star winners\n",
    "- Plot a line plot that compares the number of 5 ball, 0 star winners for in Belgium and France over April\n",
    "\n",
    "**Then, in a markdown cell** discuss briefly what this plot tells you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_codes = ['BE', 'FR']\n",
    "dates = ['02-04-2024', '05-04-2024', '09-04-2024', \n",
    "         '12-04-2024', '16-04-2024', '19-04-2024', \n",
    "         '23-04-2024', '26-04-2024', '30-04-2024']\n",
    "combined_df = stack_countries_df(country_codes, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the line plot here (you may use matplotlib or plotly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
